{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、对极几何"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<img width=500 src=\"./images/对极约束.png\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 求解本质矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/%E5%AF%B9%E6%9E%81%E5%87%A0%E4%BD%95.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gray_video import gray_video\n",
    "from core import orb_detector\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import EssentialMatrixTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相机内参为：\n",
      "[[ 1.20981082e+03 -6.38606499e-01  6.27897309e+02]\n",
      " [ 0.00000000e+00  1.18458039e+03  3.30943028e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# 相机内参\n",
    "K = np.array([[1.20981082e+03, -6.38606499e-01,  6.27897309e+02],\n",
    "              [0.00000000e+00,  1.18458039e+03,  3.30943028e+02],\n",
    "              [0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])\n",
    "print(\"相机内参为：\\n{}\".format(K))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 理论复现方法\n",
    "def resolve_essential(matched_points: np.ndarray, K: np.ndarray) -> np.ndarray:\n",
    "    K_inv = np.linalg.inv(K)\n",
    "    homogeneous_coordinates = np.ones((len(matched_points), 2, 3))\n",
    "    homogeneous_coordinates[:, :, :2] = matched_points\n",
    "    # 使用相机内参对角点坐标归一化\n",
    "    norm_curr_kps = (K_inv @ homogeneous_coordinates[:, 0].T)[:2].T\n",
    "    norm_last_kps = (K_inv @ homogeneous_coordinates[:, 1].T)[:2].T\n",
    "    # 求解本质矩阵和内点数据\n",
    "    # 使用随机采样一致性\n",
    "    model, inliers = ransac((norm_curr_kps, norm_last_kps),\n",
    "                            EssentialMatrixTransform,\n",
    "                            min_samples=8,              # 最少需要 8 个点\n",
    "                            residual_threshold=0.001,\n",
    "                            max_trials=5000)\n",
    "    E = model.params\n",
    "    # 返回本质矩阵\n",
    "    return E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def cv2_resolve_essential(img1, img2, K):\n",
    "    # opencv封装好的方法\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "\n",
    "    # ratio test as per Lowe's paper\n",
    "    for i, (m, n) in enumerate(matches):\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "\n",
    "    pts2 = np.float32(pts2)\n",
    "    pts1 = np.float32(pts1)\n",
    "\n",
    "    E, mask = cv2.findEssentialMat(pts1, pts2, K)\n",
    "    return E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_points = orb_detector.cross_detect(gray_video[0], gray_video[100])\n",
    "E_0 = resolve_essential(matched_points, K)\n",
    "E_1 = cv2_resolve_essential(gray_video[0], gray_video[100], K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.90507657  183.31556626    9.79122527]\n",
      " [-182.96078304    1.10641998  -25.10360221]\n",
      " [  -2.04065181   24.28549681    1.        ]]\n",
      "[[   2.24475872  269.28355373   29.96756523]\n",
      " [-269.93929493    3.53149948  -34.68363781]\n",
      " [ -20.61488766   33.37890993    1.        ]]\n"
     ]
    }
   ],
   "source": [
    "E_0 /= E_0[-1, -1]\n",
    "E_1 /= E_1[-1, -1]\n",
    "print(E_0)\n",
    "print(E_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到使用理论推导计算出的本质矩阵与**opencv**封装之后的函数计算出的本质矩阵有些许差别，这些差别来源于：\n",
    "1. 特征点的选取不同\n",
    "2. 重复采样一致性原理本身具有的不确定性\n",
    "3. 优化算法迭代次数的不同\n",
    "但是两者具体的数值分布具有一致性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从本质矩阵恢复相机位姿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从本质矩阵恢复相机位姿一般用本质矩阵的SVD分解得到。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E=U\\Sigma{}V^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "W=\\begin{bmatrix}\n",
    "    0 & -1 & 0 \\\\\n",
    "    1 & 0 & 0 \\\\\n",
    "    0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{l}\n",
    "     R_1 =& UWV^T\\\\\n",
    "     R_2 =& UW^TV^T\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$t$为特征值分解后最小特征值对应的$U$矩阵中向量，其中$U$、$V$需正定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_E(E: np.ndarray):\n",
    "    W = np.array(\n",
    "        [[0, -1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 1]]\n",
    "    )\n",
    "    U, S, Vt = np.linalg.svd(E)\n",
    "    R1 = U @ W @ Vt\n",
    "    R2 = U @ W.T @ Vt\n",
    "    if np.linalg.det(R1) < 0:\n",
    "        R1 = -R1\n",
    "    if np.linalg.det(R2) < 0:\n",
    "        R2 = -R2\n",
    "    t = U.T[-1]\n",
    "    return R1,R2,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "候选旋转矩阵1：\n",
      "[[ 0.99998472 -0.00290904  0.00470158]\n",
      " [ 0.00271275  0.99914604  0.04122909]\n",
      " [-0.0048175  -0.0412157   0.99913866]]\n",
      "候选旋转矩阵2：\n",
      "[[-9.64268460e-01  1.66040038e-02 -2.64406209e-01]\n",
      " [ 4.72519070e-04 -9.97924683e-01 -6.43902446e-02]\n",
      " [-2.64926618e-01 -6.22144190e-02  9.62259452e-01]]\n",
      "候选平移向量：\n",
      "[-0.13125328 -0.01170552  0.99127976]\n"
     ]
    }
   ],
   "source": [
    "R1, R2, t = decompose_E(E_0)\n",
    "print(\"候选旋转矩阵1：\\n{}\".format(R1))\n",
    "print(\"候选旋转矩阵2：\\n{}\".format(R2))\n",
    "print(\"候选平移向量：\\n{}\".format(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择正确的旋转矩阵与平移向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用计算后的位姿转换矩阵将匹配点重投影到世界坐标中，如果所有的坐标深度都为正，那这个位姿转换矩阵所对应的旋转矩阵与平移向量则最终确定为正确的旋转矩阵与平移向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 求解匹配点深度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{}^ip^\\land{}{}^ip={}^ip^{\\land}KT{}^wP=0 \\\\\n",
    "{}^ip^\\land=\\begin{bmatrix}\n",
    "    0 & -1 & v \\\\\n",
    "    1 & 0 & -u \\\\\n",
    "    -v & u & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设$KT=G$，存在约束："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "    0 & -1 & v \\\\\n",
    "    1 & 0 & -u \\\\\n",
    "    -v & u & 0 \\\\\n",
    "\\end{bmatrix}G{}^wP=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${}^ip^\\land$的秩为$2$，每个点可以为求解${}^wP$带来两个约束，使用匹配的两个点即可求得${}^wP$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_K = np.eye(4)\n",
    "normalized_K[:3,:3] = K\n",
    "normalized_K_inv = np.linalg.inv(normalized_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用三角测量计算深度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulate(matched_points, G1, G2):\n",
    "    p3ds = np.zeros((len(matched_points), 3))\n",
    "    for i in range(len(matched_points)):\n",
    "        point1 = matched_points[i][0]\n",
    "        point2 = matched_points[i][1]\n",
    "        A = np.zeros((4, 4))\n",
    "        A[0] = point1[0] * G1[2] - G1[0]\n",
    "        A[1] = point1[1] * G1[2] - G1[1]\n",
    "        A[2] = point2[0] * G2[2] - G2[0]\n",
    "        A[3] = point2[1] * G2[2] - G2[1]\n",
    "        U, S, Vt = np.linalg.svd(A)\n",
    "        p4d = Vt[-1]\n",
    "        p3ds[i] = (p4d / p4d[-1])[:3].T\n",
    "    return p3ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 验证R、T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_G(R,t,K):\n",
    "    T = np.zeros((3, 4))\n",
    "    T[:,:3]= R\n",
    "    T[:,3]= t\n",
    "    G = K@T\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_Rt(R, t, K, matched_points):\n",
    "    # 第一个相机的位姿\n",
    "    R1 = np.eye(3)\n",
    "    t1 = np.zeros((3))\n",
    "    G1 = generate_G(R1, t1, K)\n",
    "    # 第二个相机的位姿\n",
    "    G2 = generate_G(R, t, K)\n",
    "    # 三角测量算出匹配点在第一个相机下的世界坐标\n",
    "    p3ds1 = triangulate(matched_points, G1, G2)\n",
    "    # 计算匹配点在第二个相机下的世界坐标\n",
    "    p3ds2 = (R @ p3ds1.T).T + t\n",
    "\n",
    "    # 第一个相机下的匹配点世界坐标深度大于个数\n",
    "    first_good_num = (p3ds1[:, -1] < 0).sum()\n",
    "    # 第二个相机下的匹配点世界坐标深度是否大部分都大于0\n",
    "    second_good_num = (p3ds2[:, -1] < 0).sum()\n",
    "\n",
    "    return (first_good_num, second_good_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "匹配点总对数为：\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "print(\"匹配点总对数为：\")\n",
    "print(len(matched_points))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对于R1,t计算出深度为负的个数为：\n",
      "(146, 144)\n"
     ]
    }
   ],
   "source": [
    "result = check_Rt(R1, t, K, matched_points)\n",
    "print(\"对于R1,t计算出深度为负的个数为：\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对于R1,-t计算出深度为负的个数为：\n",
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "result = check_Rt(R1, -t, K, matched_points)\n",
    "print(\"对于R1,-t计算出深度为负的个数为：\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对于R2,t计算出深度为负的个数为：\n",
      "(147, 1)\n"
     ]
    }
   ],
   "source": [
    "result = check_Rt(R2, t, K, matched_points)\n",
    "print(\"对于R2,t计算出深度为负的个数为：\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对于R2,-t计算出深度为负的个数为：\n",
      "(1, 147)\n"
     ]
    }
   ],
   "source": [
    "result = check_Rt(R2, -t, K, matched_points)\n",
    "print(\"对于R2,-t计算出深度为负的个数为：\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于$R_1$、$-t$来说，计算得出世界坐标下点值为负数的个数最少，因此选择这一对参数作为相机外参。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1为：\n",
      "[[ 0.99998472 -0.00290904  0.00470158]\n",
      " [ 0.00271275  0.99914604  0.04122909]\n",
      " [-0.0048175  -0.0412157   0.99913866]]\n",
      "-t为：\n",
      "[ 0.13125328  0.01170552 -0.99127976]\n"
     ]
    }
   ],
   "source": [
    "print(\"R1为：\")\n",
    "print(R1)\n",
    "print(\"-t为：\")\n",
    "print(-t)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6fff98fc3b3d81bd655c2cc48858186e4d9e2db7b515bf1c3221888f12a62f87"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
